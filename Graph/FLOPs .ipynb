{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf8cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mahfujurrahman/Desktop/Thesis/ultralytics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahfujurrahman/Desktop/Thesis/thesis/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "%cd ..\n",
    "sys.path.append(os.path.join(os.getcwd(),'ultralytics/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fbfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8b3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline=YOLO('Graph/properties/Test_2/weights/best.pt')\n",
    "ca=YOLO('Graph/properties/Test_3/weights/best.pt')\n",
    "eca=YOLO('Graph/properties/Test_4/weights/best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4a1674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Generated by ChatGPT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "def conv_layer_flops(layer, input, output):\n",
    "    output_height, output_width = output.shape[2], output.shape[3]\n",
    "    kernel_height, kernel_width = layer.kernel_size\n",
    "    in_channels = layer.in_channels\n",
    "    out_channels = layer.out_channels\n",
    "    return 2 * kernel_height * kernel_width * in_channels * out_channels * output_height * output_width\n",
    "def conv1d_layer_flops(layer, input, output):\n",
    "    output_length = output.shape[2]\n",
    "    kernel_length = layer.kernel_size[0]\n",
    "    in_channels = layer.in_channels\n",
    "    out_channels = layer.out_channels\n",
    "    return 2 * kernel_length * in_channels * out_channels * output_length\n",
    "\n",
    "def sigmoid_layer_flops(layer, input, output):\n",
    "    return output.numel() \n",
    "\n",
    "def bn_layer_flops(layer, input, output):\n",
    "    return 2 * output.numel()  # Scaling and shifting\n",
    "\n",
    "def relu_layer_flops(layer, input, output):\n",
    "    return output.numel()\n",
    "\n",
    "def fc_layer_flops(layer, input, output):\n",
    "    return 2 * input.shape[1] * output.shape[1]\n",
    "\n",
    "def register_hooks(model):\n",
    "    flops = []\n",
    "\n",
    "    def hook_conv(layer, input, output):\n",
    "        flops.append(conv_layer_flops(layer, input[0], output))\n",
    "        \n",
    "    def hook_conv1d(layer, input, output):\n",
    "        flops.append(conv1d_layer_flops(layer, input[0], output))\n",
    "\n",
    "    def hook_bn(layer, input, output):\n",
    "        flops.append(bn_layer_flops(layer, input[0], output))\n",
    "\n",
    "    def hook_relu(layer, input, output):\n",
    "        flops.append(relu_layer_flops(layer, input[0], output))\n",
    "\n",
    "    def hook_sigmoid(layer, input, output):\n",
    "        flops.append(sigmoid_layer_flops(layer, input[0], output))\n",
    "\n",
    "    def hook_fc(layer, input, output):\n",
    "        flops.append(fc_layer_flops(layer, input[0], output))\n",
    "\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            layer.register_forward_hook(hook_conv)\n",
    "        elif isinstance(layer, nn.Conv1d):\n",
    "            layer.register_forward_hook(hook_conv1d)\n",
    "        elif isinstance(layer, nn.BatchNorm2d) or isinstance(layer, nn.BatchNorm1d):\n",
    "            layer.register_forward_hook(hook_bn)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            layer.register_forward_hook(hook_relu)\n",
    "        elif isinstance(layer, nn.Sigmoid):\n",
    "            layer.register_forward_hook(hook_sigmoid)\n",
    "        elif isinstance(layer, nn.Linear):\n",
    "            layer.register_forward_hook(hook_fc)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# def get_flops(model):\n",
    "#     flops = register_hooks(model)\n",
    "#     input_tensor = torch.randn(1, 3, 640, 640)\n",
    "#     output = model(input_tensor)\n",
    "#     total_flops = sum(flops)\n",
    "#     print(f\"Total FLOPs: {total_flops}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca71979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.842496395111084. Dividing input by 255.\n",
      "0: 640x640 (no detections), 113.7ms\n",
      "Speed: 0.0ms preprocess, 113.7ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Baseline Model Total FLOPs: 8082739200\n"
     ]
    }
   ],
   "source": [
    "flops = register_hooks(baseline)\n",
    "input_tensor = torch.randn(1, 3, 640, 640)\n",
    "output = baseline(input_tensor)\n",
    "total_flops = sum(flops)\n",
    "print(f\"Baseline Model Total FLOPs: {total_flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8779614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.85646390914917. Dividing input by 255.\n",
      "0: 640x640 (no detections), 111.6ms\n",
      "Speed: 0.0ms preprocess, 111.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Baseline Model Total FLOPs: 8082944576\n"
     ]
    }
   ],
   "source": [
    "flops = register_hooks(ca)\n",
    "input_tensor = torch.randn(1, 3, 640, 640)\n",
    "output = ca(input_tensor)\n",
    "total_flops = sum(flops)\n",
    "print(f\"Baseline Model Total FLOPs: {total_flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb4ebb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 4.918483257293701. Dividing input by 255.\n",
      "0: 640x640 (no detections), 111.4ms\n",
      "Speed: 0.0ms preprocess, 111.4ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Baseline Model Total FLOPs: 8082743232\n"
     ]
    }
   ],
   "source": [
    "flops = register_hooks(eca)\n",
    "input_tensor = torch.randn(1, 3, 640, 640)\n",
    "output = eca(input_tensor)\n",
    "total_flops = sum(flops)\n",
    "print(f\"Baseline Model Total FLOPs: {total_flops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0365b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
